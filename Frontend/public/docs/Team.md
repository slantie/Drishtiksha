# Meet the Drishtiksha Team

## Overview

The Drishtiksha platform is the product of a dedicated, cross-functional team of student interns. Our collective expertise spans the full stack, from cutting-edge deep learning and computer vision to robust backend architecture and intuitive frontend design. We are passionate about leveraging technology to solve complex, real-world problems and are united by the mission to build a more authentic digital world.

This document introduces the core members of the team, their key contributions, and the expertise they brought to this project.

---

## Core Team Members

### Kandarp Gajjar

| ![Kandarp Gajjar](Member-1.jpg) | <div style="font-size: 1.1em;">• **Role:** AI/ML & Full-Stack Solutions Architect <br/> • **Affiliation:** LDRP Institute of Technology & Research, Kadi Sarva Vishwavidayala, Gujarat <br/> • **Expertise:** System Architecture, End-to-End Development, MLOps & Deployment <br/> • **Connect:** [LinkedIn](https://www.linkedin.com/in/kandarpgajjar/) • [GitHub](https://github.com/slantie)</div> |
| :------------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Strengths**                   | • Designing the end-to-end microservice architecture for the entire platform. <br/> • Developing the responsive React frontend and the robust, asynchronous Node.js backend. <br/> • Integrating complex AI models (ColorCues, MFF-MoE) into a cohesive, scalable system.                                                                                                                              |
| **Tech Stack**                  | PyTorch, FastAPI, Node.js, Express.js, React, PostgreSQL, Redis, Docker, Nginx.                                                                                                                                                                                                                                                                                                                        |
| **Project Takeaways**           | "This project was a masterclass in system integration. The biggest challenge and learning was designing the asynchronous workflow between the frontend, backend, and ML server to handle long-running tasks gracefully. Implementing the real-time feedback loop with WebSockets and Redis Pub/Sub was critical to creating a responsive user experience and a truly production-grade system."         |

---

### Oum Gadani

| ![Oum Gadani](Member-2.jpg) | <div style="font-size: 1.1em;">• **Role:** AI/ML Developer <br/> • **Affiliation:** LDRP Institute of Technology & Research, Kadi Sarva Vishwavidayala, Gujarat <br/> • **Expertise:** Temporal Video Analysis, Audio Signal Processing, Behavioral Biometrics <br/> • **Connect:** [LinkedIn](https://www.linkedin.com/in/oumgadani/) • [GitHub](https://github.com/Oum-Gadani)</div>    |
| :-------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Strengths**               | • Implementing and training models focused on behavioral cues like the EyeBlink CNN-LSTM. <br/> • Developing audio forensic detectors using advanced spectrogram analysis (STFT & MEL). <br/> • Optimizing data preprocessing pipelines for both video and audio streams to ensure model accuracy.                                                                                        |
| **Tech Stack**              | PyTorch, Librosa, OpenCV, Kymatio, Scikit-learn, Python, Git.                                                                                                                                                                                                                                                                                                                             |
| **Project Takeaways**       | "Working on both video and audio models highlighted the importance of detecting subtle, often imperceptible cues. My key takeaway was understanding how different artifacts manifest—whether as unnatural blinks in a video or frequency distortions in an audio spectrogram. Building models to capture these distinct signals was a fantastic challenge in specialized AI development." |

---

### Raj Mathuria

| ![Raj Mathuria](Member-3.jpg) | <div style="font-size: 1.1em;">• **Role:** AI/ML Developer <br/> • **Affiliation:** Sardar Patel Institute of Technology, Maharastra <br/> • **Expertise:** Generative Model Detection, Transformer-based Temporal Analysis, Wavelet Transforms <br/> • **Connect:** [LinkedIn](https://www.linkedin.com/in/raj-mathuria-98a710283/) • [GitHub](https://github.com/CodeCraftsmanRaj)</div>                                                                |
| :---------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Strengths**                 | • Pioneering the integration of diffusion-based detection techniques with the DistilDIRE model. <br/> • Implementing the flagship temporal model (SIGLIP-LSTM) for state-of-the-art video analysis. <br/> • Developing advanced audio forensic models using wavelet scattering transforms (Scattering Wave).                                                                                                                                              |
| **Tech Stack**                | PyTorch, Hugging Face Transformers, Kymatio, Timm, OpenCV, Python, Git.                                                                                                                                                                                                                                                                                                                                                                                   |
| **Project Takeaways**         | "This project demonstrated that there is no 'one-size-fits-all' solution for deepfake detection. My takeaway is that a diverse arsenal of models is crucial. Deepfakes created by GANs, Diffusion Models, or Voice Cloning all leave different fingerprints. By implementing detectors for each of these modalities (DistilDIRE for diffusion, SIGLIP for temporal, Scattering Wave for audio), we built a much more resilient and comprehensive system." |

---

### Vishwajit Sarnobat

| ![Vishwajit Sarnobat](Member-4.jpg) | <div style="font-size: 1.1em;">• **Role:** AI/ML Developer <br/> • **Affiliation:** Sardar Patel Institute of Technology, Maharastra <br/> • **Expertise:** Advanced Computer Vision, Transformer Architectures (ViT), Multimodal Analysis <br/> • **Connect:** [LinkedIn](https://www.linkedin.com/in/vishwajitsarnobat/) • [GitHub](https://github.com/vishwajitsarnobat)</div>                                                        |
| :---------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Strengths**                       | • Leading the implementation of cutting-edge vision transformers like the Cross-EfficientNet-ViT. <br/> • Developing the multimodal LipFD detector, which correlates audio and visual streams for lip-sync analysis. <br/> • Fine-tuning high-performance classifiers like EfficientNet-B7 for granular, per-frame detection.                                                                                                            |
| **Tech Stack**                      | PyTorch, Timm, OpenCV, Scikit-learn, Python, Git.                                                                                                                                                                                                                                                                                                                                                                                        |
| **Project Takeaways**               | "My focus on multimodal models like LipFD was incredibly insightful. The key learning was that some of the most convincing deepfakes are exposed when you analyze multiple data streams simultaneously. A video might look perfect, and the audio might sound perfect, but when a model checks if the lip movements precisely match the audio phonemes, the forgery becomes apparent. This fusion of senses is the future of detection." |

---

## Acknowledgements

<!-- To be added -->
